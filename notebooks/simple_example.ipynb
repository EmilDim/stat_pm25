{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn-ticks', 'seaborn-talk'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Here, we take some of the archived data from Fernando's IGSM-CAM-GEOS-Chem ensemble and re-process it a bit to create a simpler dataset for playing with statistical meteorology-PM2.5 relationships. We similarly will extract some of Lu Shen's post-processed observational data, which he used in his 2017 paper.\n",
    "\n",
    "Our major goal here is to subset the data for a small box around Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (dec: 3, ic: 5, lat: 15, lon: 24, pol: 3, time: 359)\n",
       "Coordinates:\n",
       "  * pol      (pol) object 'REF' 'P37' 'P45'\n",
       "    cs       int64 ...\n",
       "  * ic       (ic) int64 1 2 3 4 5\n",
       "  * dec      (dec) object '1980-2010' '2035-2065' '2085-2115'\n",
       "  * lat      (lat) float64 23.68 25.58 27.47 29.37 31.26 33.16 35.05 36.95 ...\n",
       "  * lon      (lon) float64 -125.0 -122.5 -120.0 -117.5 -115.0 -112.5 -110.0 ...\n",
       "  * time     (time) datetime64[ns] 1981-01-01 1981-02-01 1981-03-01 ...\n",
       "    lev      float64 ...\n",
       "Data variables:\n",
       "    PM25     (pol, ic, dec, time, lat, lon) float64 ...\n",
       "    TEMP     (pol, ic, dec, time, lat, lon) float64 ...\n",
       "    PRECIP   (pol, ic, dec, time, lat, lon) float64 ...\n",
       "    RH       (pol, ic, dec, time, lat, lon) float64 ...\n",
       "    U        (pol, ic, dec, time, lat, lon) float64 ...\n",
       "    V        (pol, ic, dec, time, lat, lon) float64 ...\n",
       "Attributes:\n",
       "    History:  Generated by 09_lu_shen_reproduction.ipynb (Apr 19, 2017 13:49)\\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgm_ensemble = xr.open_dataset(\"../data/fgm.all_cases.usa_subset.nc\")\n",
    "fgm_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 1795)>\n",
       "array(['1981-01-01T00:00:00.000000000', '1981-02-01T00:00:00.000000000',\n",
       "       '1981-03-01T00:00:00.000000000', ..., '2126-09-01T00:00:00.000000000',\n",
       "       '2126-10-01T00:00:00.000000000', '2126-11-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "    lev      float64 992.6\n",
       "    ic       (time) int64 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...\n",
       "  * time     (time) datetime64[ns] 1981-01-01 1981-02-01 1981-03-01 ...\n",
       "Attributes:\n",
       "    long_name:  time\n",
       "    bounds:     time_bnds"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgm_ensemble.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example\n",
    "\n",
    "For a simple example of how to use this toolkit, let's look at the following simple Principal Component Regression model, adapted from the example in [stat_pm25/models/simple.py]():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     2,
     40
    ]
   },
   "outputs": [],
   "source": [
    "from stat_pm25.sklearn import *\n",
    "\n",
    "class PCRModel(DatasetModel):\n",
    "    \"\"\" Performs principal component regression model on gridded data.\n",
    "\n",
    "    This class uses the `DatasetModel` framework to implement a principal\n",
    "    component regression - a linear regression on a set of features which has\n",
    "    been pre-processed using principal component analysis. It only requires a\n",
    "    single additional argument on top of `DatasetModel`, the number of\n",
    "    components to retain.\n",
    "\n",
    "    This example illustrates how you can very easily put together complex\n",
    "    analyses and deploy them onto your gridded model output, all using very\n",
    "    simple building blocks.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, n_components=3, **kwargs):\n",
    "        # If you need to add arguments, add them as named keyword arguments in\n",
    "        # the appropriate place (as shown above), and set them first in the\n",
    "        # method.\n",
    "        self.n_components = n_components\n",
    "\n",
    "        # Modify any pre-set parameters, or hard-code them otherwise. For\n",
    "        # instance, if you want to pre-process your data, this would be the\n",
    "        # place to specify how to do so. Doing so here has the advantage that\n",
    "        # you will be able to immediately apply your `predict()` method\n",
    "        # to new data without pre-processing it - all that logic will be\n",
    "        # saved\n",
    "\n",
    "        # Zero out dilat and dilon, since we don't need to search around\n",
    "        # neighboring grid cells\n",
    "        self.dilat = self.dilon = 0\n",
    "\n",
    "        # Set a pre-processor pipeline\n",
    "        self.preprocessor = None\n",
    "        \n",
    "        # Call the parent superconstructor\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def cell_kernel(self, gcf):\n",
    "        \"\"\" Fit a model at a single grid cell.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # First, get the predictand data at the grid cell we care about. We\n",
    "        # don't necessarily have to be super pedantic about this; we can just\n",
    "        # use normal xarray selection methods if we want, although comments\n",
    "        # below is how we could accomplish this using our specialized\n",
    "        # Transformer classes\n",
    "        # local_selector = DatasetSelector(\n",
    "        #     sel='isel', lon=gcf.ilon, lat=gcf.ilat\n",
    "        # )\n",
    "        # y = local_selector.fit_transform(self.data[self.predictand])\n",
    "        y = self.data[self.predictand].isel(lat=gcf.ilat, lon=gcf.ilon)\n",
    "\n",
    "        # Prepare features timeseries. We want to fully include all the steps\n",
    "        # to extract our features from the original, full dataset in here\n",
    "        # so that our logic for re-applying the pipeline for prediction\n",
    "        # later on will work similarly\n",
    "        _model = Pipeline([\n",
    "            ('subset_latlon', DatasetSelector(\n",
    "                sel='isel', lon=gcf.ilon, lat=gcf.ilat)\n",
    "            ),\n",
    "            ('predictors', FieldExtractor(self.predictors)),\n",
    "            ('normalize', Normalizer()),\n",
    "            ('dataset_to_array', DatasetAdapter(drop=['lat', 'lon'])),\n",
    "            ('pca', PCA(n_components=self.n_components)),\n",
    "            ('linear', LinearRegression()),\n",
    "        ])\n",
    "\n",
    "        # Fit the model/pipeline\n",
    "        _model.fit(self.data, y)\n",
    "        # Calculate some sort of score for archival\n",
    "        _score = _model.score(self.data, y)\n",
    "        # Encapsulate the result within a GridCellResukt\n",
    "        gcr = GridCellResult(_model, self.predictand, self.predictors, _score)\n",
    "\n",
    "        return gcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between this and the original, saved version is that I've excluded the pre-processing step - we can do that on our own."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
